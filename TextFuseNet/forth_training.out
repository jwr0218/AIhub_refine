Config 'configs/ocr/icdar2015_101_FPN.yaml' has no VERSION. Assuming it to be compatible with latest v2.
Command Line Args: Namespace(config_file='configs/ocr/icdar2015_101_FPN.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=True)
[32m[10/19 07:26:13 detectron2]: [0mRank of current process: 0. World size: 1
[32m[10/19 07:26:14 detectron2]: [0mEnvironment info:
------------------------  ---------------------------------------------------
sys.platform              linux
Python                    3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
Numpy                     1.21.2
Detectron2 Compiler       GCC 7.5
Detectron2 CUDA Compiler  11.3
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.11.0
PyTorch Debug Build       False
torchvision               0.12.0
CUDA available            True
GPU 0                     NVIDIA RTX A4000
CUDA_HOME                 /usr/local/cuda
NVCC                      Build cuda_11.3.r11.3/compiler.29920130_0
Pillow                    9.0.1
cv2                       4.3.0
------------------------  ---------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[32m[10/19 07:26:14 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/ocr/icdar2015_101_FPN.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=True)
[32m[10/19 07:26:14 detectron2]: [0mContents of args.config_file=configs/ocr/icdar2015_101_FPN.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: True
  TEXTFUSENET_MUTIL_PATH_FUSE_ON: True
  WEIGHTS: "./out_dir_r101/icdar2015_model/model_ic15_r101.pth"
  PIXEL_STD: [57.375, 57.120, 58.395]
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 101
  ROI_HEADS:
    NMS_THRESH_TEST: 0.35
  TEXTFUSENET_SEG_HEAD:
    FPN_FEATURES_FUSED_LEVEL: 2
    POOLER_SCALES: (0.0625,)

DATASETS:
  TRAIN: ("aihub_korean_train",)
  TEST: ("aihub_korean_validation",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.001
  STEPS: (40000,80000,)
  MAX_ITER: 91000
  CHECKPOINT_PERIOD: 2500

INPUT:
  MIN_SIZE_TRAIN: (800,1000,1200)
  MAX_SIZE_TRAIN: 1500
  MIN_SIZE_TEST: 1500
  MAX_SIZE_TEST: 3000
  

OUTPUT_DIR: "./out_dir_r101/icdar2015_model/"

[32m[10/19 07:26:14 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('aihub_korean_validation',)
  TRAIN: ('aihub_korean_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 3000
  MAX_SIZE_TRAIN: 1500
  MIN_SIZE_TEST: 1500
  MIN_SIZE_TRAIN: (800, 1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.35
    NUM_CLASSES: 63
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  TEXTFUSENET_MUTIL_PATH_FUSE_ON: True
  TEXTFUSENET_SEG_HEAD:
    CHANNELS: 256
    FPN_FEATURES_FUSED_LEVEL: 2
    NUM_CLASSES: 2
    NUM_CONV3: 4
    NUM_FPN_FEATURES: 4
    POOLER_RESOLUTION: 14
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    SAMPLING_RATIO: 2
  WEIGHTS: ./out_dir_r101/icdar2015_model/model_ic15_r101.pth
OUTPUT_DIR: ./out_dir_r101/icdar2015_model/
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 91000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[32m[10/19 07:26:14 detectron2]: [0mFull config saved to /workspace/TextDetection/TextFuseNet/out_dir_r101/icdar2015_model/config.yaml
[32m[10/19 07:26:14 d2.utils.env]: [0mUsing a generated random seed 14941049
[32m[10/19 07:26:19 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=64, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=252, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=2, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=2, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=2, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (predictor): Conv2d(256, 63, kernel_size=(1, 1), stride=(1, 1))
    )
    (seg_head): Segmentation_head(
      (conv1x1_list): ModuleList(
        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)
        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)
        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (conv3x3_list): ModuleList(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (seg_pooler): ROIPooler(
        (level_poolers): ModuleList(
          (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=2, aligned=True)
        )
      )
      (conv3x3_list_roi): ModuleList(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (conv1x1_seg_logits): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (seg_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mutil_path_fuse_module): Mutil_Path_Fuse_Module(
      (char_conv3x3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (char_conv1x1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (text_conv3x3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (text_conv1x1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv3x3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (conv1x1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
)
[32m[10/19 07:26:19 d2.data.datasets.coco]: [0mLoaded 25690 images in COCO format from ./datasets_aihub/training/train.json
[32m[10/19 07:26:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 25690 images left.
[32m[10/19 07:26:20 d2.data.build]: [0mDistribution of training instances among all 63 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    text    | 42669        |     0      | 0            |     1      | 0            |
|     2      | 0            |     3      | 0            |     4      | 0            |
|     5      | 0            |     6      | 0            |     7      | 0            |
|     8      | 0            |     9      | 0            |     A      | 0            |
|     B      | 0            |     C      | 0            |     D      | 0            |
|     E      | 0            |     F      | 0            |     G      | 0            |
|     H      | 0            |     I      | 0            |     J      | 0            |
|     K      | 0            |     L      | 0            |     M      | 0            |
|     N      | 0            |     O      | 0            |     P      | 0            |
|     Q      | 0            |     R      | 0            |     S      | 0            |
|     T      | 0            |     U      | 0            |     V      | 0            |
|     W      | 0            |     X      | 0            |     Y      | 0            |
|     Z      | 0            |     a      | 0            |     b      | 0            |
|     c      | 0            |     d      | 0            |     e      | 0            |
|     f      | 0            |     g      | 0            |     h      | 0            |
|     i      | 0            |     j      | 0            |     k      | 0            |
|     l      | 0            |     m      | 0            |     n      | 0            |
|     o      | 0            |     p      | 0            |     q      | 0            |
|     r      | 0            |     s      | 0            |     t      | 0            |
|     u      | 0            |     v      | 0            |     w      | 0            |
|     x      | 0            |     y      | 0            |     z      | 0            |
|            |              |            |              |            |              |
|   total    | 42669        |            |              |            |              |[0m
[32m[10/19 07:26:20 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(800, 1000, 1200), max_size=1500, sample_style='choice'), RandomFlip(), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomLighting(scale=1.133372022496665)]
[32m[10/19 07:26:20 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[10/19 07:26:23 fvcore.common.checkpoint]: [0mLoading checkpoint from ./out_dir_r101/icdar2015_model/model_final.pth
[32m[10/19 07:26:24 fvcore.common.checkpoint]: [0mLoading optimizer from ./out_dir_r101/icdar2015_model/model_final.pth
[32m[10/19 07:26:24 fvcore.common.checkpoint]: [0mLoading scheduler from ./out_dir_r101/icdar2015_model/model_final.pth
[32m[10/19 07:26:24 d2.engine.train_loop]: [0mStarting training from iteration 90000
[32m[10/19 07:26:37 d2.utils.events]: [0meta: 0:10:16  iter: 90019  total_loss: 0.097  loss_cls: 0.010  loss_box_reg: 0.011  loss_mask: 0.041  loss_seg: 0.029  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.6386  data_time: 0.0017  lr: 0.000010  max_mem: 10665M
[32m[10/19 07:26:51 d2.utils.events]: [0meta: 0:10:07  iter: 90039  total_loss: 0.081  loss_cls: 0.006  loss_box_reg: 0.006  loss_mask: 0.025  loss_seg: 0.016  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.6614  data_time: 0.0021  lr: 0.000010  max_mem: 12428M
[32m[10/19 07:27:03 d2.utils.events]: [0meta: 0:09:54  iter: 90059  total_loss: 0.118  loss_cls: 0.014  loss_box_reg: 0.012  loss_mask: 0.042  loss_seg: 0.019  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.6441  data_time: 0.0021  lr: 0.000010  max_mem: 12428M
[32m[10/19 07:27:16 d2.utils.events]: [0meta: 0:09:46  iter: 90079  total_loss: 0.059  loss_cls: 0.005  loss_box_reg: 0.006  loss_mask: 0.016  loss_seg: 0.010  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 0.6364  data_time: 0.0022  lr: 0.000010  max_mem: 12428M
[32m[10/19 07:27:30 d2.utils.events]: [0meta: 0:09:41  iter: 90099  total_loss: 0.091  loss_cls: 0.008  loss_box_reg: 0.007  loss_mask: 0.022  loss_seg: 0.019  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.6525  data_time: 0.0020  lr: 0.000010  max_mem: 12428M
[32m[10/19 07:27:44 d2.utils.events]: [0meta: 0:09:32  iter: 90119  total_loss: 0.108  loss_cls: 0.007  loss_box_reg: 0.010  loss_mask: 0.027  loss_seg: 0.021  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.6620  data_time: 0.0021  lr: 0.000010  max_mem: 12435M
[32m[10/19 07:27:56 d2.utils.events]: [0meta: 0:09:15  iter: 90139  total_loss: 0.135  loss_cls: 0.011  loss_box_reg: 0.014  loss_mask: 0.030  loss_seg: 0.022  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.6539  data_time: 0.0021  lr: 0.000010  max_mem: 12435M
[32m[10/19 07:28:10 d2.utils.events]: [0meta: 0:09:05  iter: 90159  total_loss: 0.147  loss_cls: 0.009  loss_box_reg: 0.012  loss_mask: 0.030  loss_seg: 0.029  loss_rpn_cls: 0.001  loss_rpn_loc: 0.021  time: 0.6548  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:28:23 d2.utils.events]: [0meta: 0:08:53  iter: 90179  total_loss: 0.054  loss_cls: 0.006  loss_box_reg: 0.005  loss_mask: 0.015  loss_seg: 0.014  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 0.6537  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:28:35 d2.utils.events]: [0meta: 0:08:39  iter: 90199  total_loss: 0.119  loss_cls: 0.013  loss_box_reg: 0.012  loss_mask: 0.034  loss_seg: 0.019  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 0.6506  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:28:48 d2.utils.events]: [0meta: 0:08:26  iter: 90219  total_loss: 0.080  loss_cls: 0.006  loss_box_reg: 0.007  loss_mask: 0.019  loss_seg: 0.016  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.6515  data_time: 0.0019  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:29:00 d2.utils.events]: [0meta: 0:08:11  iter: 90239  total_loss: 0.102  loss_cls: 0.005  loss_box_reg: 0.008  loss_mask: 0.032  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.018  time: 0.6450  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:29:14 d2.utils.events]: [0meta: 0:08:00  iter: 90259  total_loss: 0.066  loss_cls: 0.007  loss_box_reg: 0.005  loss_mask: 0.017  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 0.6473  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:29:26 d2.utils.events]: [0meta: 0:07:45  iter: 90279  total_loss: 0.098  loss_cls: 0.006  loss_box_reg: 0.006  loss_mask: 0.020  loss_seg: 0.028  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.6443  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:29:39 d2.utils.events]: [0meta: 0:07:33  iter: 90299  total_loss: 0.121  loss_cls: 0.007  loss_box_reg: 0.013  loss_mask: 0.041  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 0.6442  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:29:51 d2.utils.events]: [0meta: 0:07:19  iter: 90319  total_loss: 0.123  loss_cls: 0.009  loss_box_reg: 0.017  loss_mask: 0.037  loss_seg: 0.020  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.6419  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:30:05 d2.utils.events]: [0meta: 0:07:06  iter: 90339  total_loss: 0.124  loss_cls: 0.015  loss_box_reg: 0.008  loss_mask: 0.018  loss_seg: 0.029  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 0.6463  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:30:19 d2.utils.events]: [0meta: 0:06:53  iter: 90359  total_loss: 0.057  loss_cls: 0.006  loss_box_reg: 0.006  loss_mask: 0.016  loss_seg: 0.015  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 0.6477  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:30:33 d2.utils.events]: [0meta: 0:06:42  iter: 90379  total_loss: 0.153  loss_cls: 0.019  loss_box_reg: 0.015  loss_mask: 0.028  loss_seg: 0.034  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.6517  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:30:47 d2.utils.events]: [0meta: 0:06:30  iter: 90399  total_loss: 0.102  loss_cls: 0.006  loss_box_reg: 0.007  loss_mask: 0.022  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 0.6526  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:31:00 d2.utils.events]: [0meta: 0:06:17  iter: 90419  total_loss: 0.171  loss_cls: 0.009  loss_box_reg: 0.014  loss_mask: 0.036  loss_seg: 0.025  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.6534  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:31:14 d2.utils.events]: [0meta: 0:06:04  iter: 90439  total_loss: 0.061  loss_cls: 0.005  loss_box_reg: 0.008  loss_mask: 0.013  loss_seg: 0.027  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 0.6552  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:31:26 d2.utils.events]: [0meta: 0:05:51  iter: 90459  total_loss: 0.084  loss_cls: 0.006  loss_box_reg: 0.009  loss_mask: 0.031  loss_seg: 0.019  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 0.6529  data_time: 0.0021  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:31:39 d2.utils.events]: [0meta: 0:05:37  iter: 90479  total_loss: 0.034  loss_cls: 0.005  loss_box_reg: 0.004  loss_mask: 0.014  loss_seg: 0.009  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.6518  data_time: 0.0020  lr: 0.000010  max_mem: 12461M
[32m[10/19 07:31:53 d2.utils.events]: [0meta: 0:05:24  iter: 90499  total_loss: 0.115  loss_cls: 0.014  loss_box_reg: 0.008  loss_mask: 0.018  loss_seg: 0.028  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.6540  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:32:06 d2.utils.events]: [0meta: 0:05:12  iter: 90519  total_loss: 0.100  loss_cls: 0.007  loss_box_reg: 0.010  loss_mask: 0.026  loss_seg: 0.021  loss_rpn_cls: 0.001  loss_rpn_loc: 0.021  time: 0.6532  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:32:19 d2.utils.events]: [0meta: 0:04:59  iter: 90539  total_loss: 0.076  loss_cls: 0.008  loss_box_reg: 0.003  loss_mask: 0.015  loss_seg: 0.021  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 0.6536  data_time: 0.0021  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:32:31 d2.utils.events]: [0meta: 0:04:45  iter: 90559  total_loss: 0.095  loss_cls: 0.013  loss_box_reg: 0.008  loss_mask: 0.021  loss_seg: 0.021  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.6513  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:32:44 d2.utils.events]: [0meta: 0:04:33  iter: 90579  total_loss: 0.077  loss_cls: 0.007  loss_box_reg: 0.006  loss_mask: 0.017  loss_seg: 0.022  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 0.6514  data_time: 0.0021  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:32:57 d2.utils.events]: [0meta: 0:04:20  iter: 90599  total_loss: 0.111  loss_cls: 0.012  loss_box_reg: 0.009  loss_mask: 0.031  loss_seg: 0.020  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  time: 0.6504  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:33:10 d2.utils.events]: [0meta: 0:04:07  iter: 90619  total_loss: 0.101  loss_cls: 0.009  loss_box_reg: 0.011  loss_mask: 0.036  loss_seg: 0.019  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.6511  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:33:22 d2.utils.events]: [0meta: 0:03:54  iter: 90639  total_loss: 0.094  loss_cls: 0.008  loss_box_reg: 0.008  loss_mask: 0.023  loss_seg: 0.019  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 0.6491  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:33:35 d2.utils.events]: [0meta: 0:03:41  iter: 90659  total_loss: 0.111  loss_cls: 0.008  loss_box_reg: 0.009  loss_mask: 0.023  loss_seg: 0.015  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.6493  data_time: 0.0018  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:33:48 d2.utils.events]: [0meta: 0:03:28  iter: 90679  total_loss: 0.037  loss_cls: 0.005  loss_box_reg: 0.005  loss_mask: 0.012  loss_seg: 0.014  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.6488  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:34:02 d2.utils.events]: [0meta: 0:03:15  iter: 90699  total_loss: 0.108  loss_cls: 0.010  loss_box_reg: 0.006  loss_mask: 0.018  loss_seg: 0.023  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.6507  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:34:15 d2.utils.events]: [0meta: 0:03:02  iter: 90719  total_loss: 0.062  loss_cls: 0.005  loss_box_reg: 0.006  loss_mask: 0.017  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 0.6510  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:34:28 d2.utils.events]: [0meta: 0:02:49  iter: 90739  total_loss: 0.082  loss_cls: 0.004  loss_box_reg: 0.008  loss_mask: 0.029  loss_seg: 0.023  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 0.6509  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:34:41 d2.utils.events]: [0meta: 0:02:36  iter: 90759  total_loss: 0.063  loss_cls: 0.004  loss_box_reg: 0.007  loss_mask: 0.016  loss_seg: 0.026  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 0.6506  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:34:53 d2.utils.events]: [0meta: 0:02:23  iter: 90779  total_loss: 0.117  loss_cls: 0.011  loss_box_reg: 0.013  loss_mask: 0.033  loss_seg: 0.022  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 0.6488  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:35:06 d2.utils.events]: [0meta: 0:02:10  iter: 90799  total_loss: 0.068  loss_cls: 0.006  loss_box_reg: 0.008  loss_mask: 0.014  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 0.6488  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:35:18 d2.utils.events]: [0meta: 0:01:57  iter: 90819  total_loss: 0.120  loss_cls: 0.011  loss_box_reg: 0.010  loss_mask: 0.026  loss_seg: 0.024  loss_rpn_cls: 0.001  loss_rpn_loc: 0.021  time: 0.6479  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:35:31 d2.utils.events]: [0meta: 0:01:44  iter: 90839  total_loss: 0.047  loss_cls: 0.004  loss_box_reg: 0.005  loss_mask: 0.014  loss_seg: 0.013  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 0.6477  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:35:45 d2.utils.events]: [0meta: 0:01:31  iter: 90859  total_loss: 0.113  loss_cls: 0.011  loss_box_reg: 0.008  loss_mask: 0.031  loss_seg: 0.018  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 0.6488  data_time: 0.0021  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:35:59 d2.utils.events]: [0meta: 0:01:18  iter: 90879  total_loss: 0.091  loss_cls: 0.007  loss_box_reg: 0.005  loss_mask: 0.016  loss_seg: 0.013  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 0.6499  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:36:12 d2.utils.events]: [0meta: 0:01:05  iter: 90899  total_loss: 0.088  loss_cls: 0.007  loss_box_reg: 0.007  loss_mask: 0.020  loss_seg: 0.019  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 0.6493  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:36:24 d2.utils.events]: [0meta: 0:00:52  iter: 90919  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.004  loss_mask: 0.011  loss_seg: 0.011  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 0.6489  data_time: 0.0019  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:36:37 d2.utils.events]: [0meta: 0:00:39  iter: 90939  total_loss: 0.107  loss_cls: 0.010  loss_box_reg: 0.014  loss_mask: 0.035  loss_seg: 0.027  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 0.6486  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:36:51 d2.utils.events]: [0meta: 0:00:26  iter: 90959  total_loss: 0.102  loss_cls: 0.008  loss_box_reg: 0.007  loss_mask: 0.022  loss_seg: 0.019  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.6493  data_time: 0.0021  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:37:03 d2.utils.events]: [0meta: 0:00:13  iter: 90979  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.005  loss_mask: 0.018  loss_seg: 0.015  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 0.6487  data_time: 0.0020  lr: 0.000010  max_mem: 12492M
[32m[10/19 07:37:17 fvcore.common.checkpoint]: [0mSaving checkpoint to ./out_dir_r101/icdar2015_model/model_final.pth
[32m[10/19 07:37:25 d2.data.datasets.coco]: [0mLoaded 3243 images in COCO format from ./datasets_aihub/validation/validation.json
[32m[10/19 07:37:25 d2.data.build]: [0mDistribution of training instances among all 63 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    text    | 5465         |     0      | 0            |     1      | 0            |
|     2      | 0            |     3      | 0            |     4      | 0            |
|     5      | 0            |     6      | 0            |     7      | 0            |
|     8      | 0            |     9      | 0            |     A      | 0            |
|     B      | 0            |     C      | 0            |     D      | 0            |
|     E      | 0            |     F      | 0            |     G      | 0            |
|     H      | 0            |     I      | 0            |     J      | 0            |
|     K      | 0            |     L      | 0            |     M      | 0            |
|     N      | 0            |     O      | 0            |     P      | 0            |
|     Q      | 0            |     R      | 0            |     S      | 0            |
|     T      | 0            |     U      | 0            |     V      | 0            |
|     W      | 0            |     X      | 0            |     Y      | 0            |
|     Z      | 0            |     a      | 0            |     b      | 0            |
|     c      | 0            |     d      | 0            |     e      | 0            |
|     f      | 0            |     g      | 0            |     h      | 0            |
|     i      | 0            |     j      | 0            |     k      | 0            |
|     l      | 0            |     m      | 0            |     n      | 0            |
|     o      | 0            |     p      | 0            |     q      | 0            |
|     r      | 0            |     s      | 0            |     t      | 0            |
|     u      | 0            |     v      | 0            |     w      | 0            |
|     x      | 0            |     y      | 0            |     z      | 0            |
|            |              |            |              |            |              |
|   total    | 5465         |            |              |            |              |[0m
[32m[10/19 07:37:25 d2.evaluation.evaluator]: [0mStart inference on 3243 images
/opt/conda/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[32m[10/19 07:37:27 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:10:48 (0.6506 s / it)
[32m[10/19 07:37:27 d2.engine.hooks]: [0mTotal training time: 0:11:01 (0:00:12 on hooks)
Traceback (most recent call last):
  File "tools/train_net.py", line 156, in <module>
    launch(
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/launch.py", line 52, in launch
    main_func(*args)
  File "tools/train_net.py", line 150, in main
    return trainer.train()
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/defaults.py", line 357, in train
    super().train(self.start_iter, self.max_iter)
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/train_loop.py", line 133, in train
    self.after_step()
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/train_loop.py", line 151, in after_step
    h.after_step()
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/hooks.py", line 323, in after_step
    results = self._func()
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/defaults.py", line 308, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/workspace/TextDetection/TextFuseNet/detectron2/engine/defaults.py", line 468, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/workspace/TextDetection/TextFuseNet/detectron2/evaluation/evaluator.py", line 120, in inference_on_dataset
    outputs = model(inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/TextDetection/TextFuseNet/detectron2/modeling/meta_arch/rcnn.py", line 66, in forward
    return self.inference(batched_inputs)
  File "/workspace/TextDetection/TextFuseNet/detectron2/modeling/meta_arch/rcnn.py", line 124, in inference
    results, _ = self.roi_heads(images, features, proposals, None)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/TextDetection/TextFuseNet/detectron2/modeling/roi_heads/roi_heads.py", line 591, in forward
    pred_instances = self.forward_with_given_boxes(features, pred_instances)
  File "/workspace/TextDetection/TextFuseNet/detectron2/modeling/roi_heads/roi_heads.py", line 616, in forward_with_given_boxes
    instances = self._forward_mask(features, instances)
  File "/workspace/TextDetection/TextFuseNet/detectron2/modeling/roi_heads/roi_heads.py", line 704, in _forward_mask
    seg_logits,global_context = self.seg_head(features, self.fpn_features_fused_level, pred_boxes, image_shape)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/TextDetection/TextFuseNet/detectron2/modeling/roi_heads/seg_head.py", line 86, in forward
    feature_pred = self.conv1x1_seg_logits(feature_pred)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 4.10 GiB (GPU 0; 15.74 GiB total capacity; 5.82 GiB already allocated; 2.69 GiB free; 11.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
